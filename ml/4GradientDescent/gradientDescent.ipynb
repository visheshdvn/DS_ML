{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Gradient Descent?\n",
    "\n",
    "Gradient descent is an optimization algorithm used in machine learning and deep learning to minimize the cost/loss function of a model by iteratively adjusting its parameters. The cost function measures the difference between the predicted output of the model and the actual output.\n",
    "\n",
    "The gradient descent algorithm works by calculating the gradient of the cost function with respect to each parameter and then adjusting the parameters in the direction of the negative gradient. This process is repeated until the algorithm reaches a minimum point of the cost function.\n",
    "\n",
    "There are two main types of gradient descent: batch gradient descent and stochastic gradient descent. In batch gradient descent, the algorithm computes the gradient of the cost function over the entire training dataset. In stochastic gradient descent, the algorithm computes the gradient over a single training example at a time.\n",
    "\n",
    "Gradient descent is a powerful optimization algorithm that is widely used in many machine learning models, such as linear regression, logistic regression, and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
